2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Current SDK version is 0.16.3
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Configure stats pid to 1739491
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Loading settings from /workspace/nathan/RWKV-LM/RWKV-v5/wandb/settings
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'RWKV-v5/train.py', 'program_abspath': '/workspace/nathan/RWKV-LM/RWKV-v5/train.py', 'program': '/workspace/nathan/RWKV-LM/RWKV-v5/train.py'}
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:_log_setup():526] Logging user logs to /workspace/nathan/RWKV-LM/RWKV-v5/wandb/run-20240328_232755-i6tkm7s9/logs/debug.log
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:_log_setup():527] Logging internal logs to /workspace/nathan/RWKV-LM/RWKV-v5/wandb/run-20240328_232755-i6tkm7s9/logs/debug-internal.log
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:init():566] calling init triggers
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {'load_model': '/checkpoint/2.25T-Base-PreFT-Chunk-v1.1-4kOptimized-P6/rwkv-init.pth', 'wandb': 'RWKV-V5-Eagle-PreFT1.1', 'proj_dir': '/checkpoint/2.25T-Base-PreFT-Chunk-v1.1-4kOptimized-P6', 'random_seed': -1, 'data_file': '/workspace/nathan/2.25T-Base-PreFT-Chunk-v1.1-4kOptimized-P6', 'data_type': 'binidx', 'vocab_size': 65536, 'ctx_len': 4096, 'epoch_steps': 120, 'epoch_count': 24, 'epoch_begin': 0, 'epoch_save': 3, 'micro_bsz': 14, 'n_layer': 32, 'n_embd': 4096, 'dim_att': 4096, 'dim_ffn': 14336, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'lr_init': 6e-06, 'lr_final': 5.5e-06, 'warmup_steps': 0, 'beta1': 0.9, 'beta2': 0.99, 'adam_eps': 1e-08, 'grad_cp': 1, 'dropout': 0, 'weight_decay': 0.0, 'weight_decay_final': -1, 'my_pile_version': 1, 'my_pile_stage': 3, 'my_pile_shift': 0, 'my_pile_edecay': 0, 'layerwise_lr': 1, 'ds_bucket_mb': 200, 'my_sample_len': 0, 'my_ffn_shift': 1, 'my_att_shift': 1, 'head_size_a': 64, 'head_size_divisor': 8, 'my_pos_emb': 0, 'load_partial': 0, 'magic_prime': 994229, 'my_qa_mask': 0, 'my_random_steps': 0, 'my_testing': '', 'my_exit': 99999999, 'my_exit_tokens': 4072400703, 'logger': False, 'enable_checkpointing': False, 'default_root_dir': None, 'gradient_clip_val': 1.0, 'gradient_clip_algorithm': None, 'num_nodes': 3, 'num_processes': None, 'devices': '8', 'gpus': None, 'auto_select_gpus': None, 'tpu_cores': None, 'ipus': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 100000000000000000000, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': -1, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'log_every_n_steps': 100000000000000000000, 'accelerator': 'gpu', 'strategy': 'deepspeed_stage_2', 'sync_batchnorm': False, 'precision': 'bf16', 'enable_model_summary': True, 'num_sanity_val_steps': 0, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': False, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'plugins': None, 'amp_backend': None, 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'inference_mode': True, 'my_timestamp': '2024-03-28-23-24-23', 'betas': (0.9, 0.99), 'real_bsz': 336, 'run_name': '65536 ctx4096 L32 D4096'}
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:init():616] starting backend
2024-03-28 23:27:55,433 INFO    MainThread:1739491 [wandb_init.py:init():620] setting up manager
2024-03-28 23:27:55,434 INFO    MainThread:1739491 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-03-28 23:27:55,435 INFO    MainThread:1739491 [wandb_init.py:init():628] backend started and connected
2024-03-28 23:27:55,443 INFO    MainThread:1739491 [wandb_init.py:init():720] updated telemetry
2024-03-28 23:27:55,455 INFO    MainThread:1739491 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-03-28 23:27:55,917 INFO    MainThread:1739491 [wandb_run.py:_on_init():2262] communicating current version
2024-03-28 23:27:56,015 INFO    MainThread:1739491 [wandb_run.py:_on_init():2271] got version response upgrade_message: "wandb version 0.16.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-03-28 23:27:56,015 INFO    MainThread:1739491 [wandb_init.py:init():804] starting run threads in backend
2024-03-28 23:27:56,158 INFO    MainThread:1739491 [wandb_run.py:_console_start():2241] atexit reg
2024-03-28 23:27:56,158 INFO    MainThread:1739491 [wandb_run.py:_redirect():2096] redirect: wrap_raw
2024-03-28 23:27:56,158 INFO    MainThread:1739491 [wandb_run.py:_redirect():2161] Wrapping output streams.
2024-03-28 23:27:56,158 INFO    MainThread:1739491 [wandb_run.py:_redirect():2186] Redirects installed.
2024-03-28 23:27:56,160 INFO    MainThread:1739491 [wandb_init.py:init():847] run started, returning control to user process
2024-03-29 06:20:25,107 WARNING MsgRouterThr:1739491 [router.py:message_loop():77] message_loop has been closed

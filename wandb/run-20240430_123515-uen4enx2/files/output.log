INFO: GPU available: True (cuda), used: True
INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True
INFO: TPU available: False, using: 0 TPU cores
INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO: IPU available: False, using: 0 IPUs
INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs
INFO: HPU available: False, using: 0 HPUs
INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'args' removed from hparams because it cannot be pickled
INFO:pytorch_lightning.strategies.deepspeed:initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/32
INFO: Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.
INFO:lightning.pytorch.utilities.rank_zero:Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.
decay ['blocks.0.att.gate.weight', 'blocks.0.att.key.weight', 'blocks.0.att.output.weight', 'blocks.0.att.receptance.weight', 'blocks.0.att.value.weight', 'blocks.0.ffn.key.weight', 'blocks.0.ffn.receptance.weight', 'blocks.0.ffn.value.weight', 'blocks.1.att.gate.weight', 'blocks.1.att.key.weight', 'blocks.1.att.output.weight', 'blocks.1.att.receptance.weight', 'blocks.1.att.value.weight', 'blocks.1.ffn.key.weight', 'blocks.1.ffn.receptance.weight', 'blocks.1.ffn.value.weight', 'blocks.2.att.gate.weight', 'blocks.2.att.key.weight', 'blocks.2.att.output.weight', 'blocks.2.att.receptance.weight', 'blocks.2.att.value.weight', 'blocks.2.ffn.key.weight', 'blocks.2.ffn.receptance.weight', 'blocks.2.ffn.value.weight', 'blocks.3.att.gate.weight', 'blocks.3.att.key.weight', 'blocks.3.att.output.weight', 'blocks.3.att.receptance.weight', 'blocks.3.att.value.weight', 'blocks.3.ffn.key.weight', 'blocks.3.ffn.receptance.weight', 'blocks.3.ffn.value.weight', 'blocks.4.att.gate.weight', 'blocks.4.att.key.weight', 'blocks.4.att.output.weight', 'blocks.4.att.receptance.weight', 'blocks.4.att.value.weight', 'blocks.4.ffn.key.weight', 'blocks.4.ffn.receptance.weight', 'blocks.4.ffn.value.weight', 'blocks.5.att.gate.weight', 'blocks.5.att.key.weight', 'blocks.5.att.output.weight', 'blocks.5.att.receptance.weight', 'blocks.5.att.value.weight', 'blocks.5.ffn.key.weight', 'blocks.5.ffn.receptance.weight', 'blocks.5.ffn.value.weight', 'blocks.6.att.gate.weight', 'blocks.6.att.key.weight', 'blocks.6.att.output.weight', 'blocks.6.att.receptance.weight', 'blocks.6.att.value.weight', 'blocks.6.ffn.key.weight', 'blocks.6.ffn.receptance.weight', 'blocks.6.ffn.value.weight', 'blocks.7.att.gate.weight', 'blocks.7.att.key.weight', 'blocks.7.att.output.weight', 'blocks.7.att.receptance.weight', 'blocks.7.att.value.weight', 'blocks.7.ffn.key.weight', 'blocks.7.ffn.receptance.weight', 'blocks.7.ffn.value.weight', 'blocks.8.att.gate.weight', 'blocks.8.att.key.weight', 'blocks.8.att.output.weight', 'blocks.8.att.receptance.weight', 'blocks.8.att.value.weight', 'blocks.8.ffn.key.weight', 'blocks.8.ffn.receptance.weight', 'blocks.8.ffn.value.weight', 'blocks.9.att.gate.weight', 'blocks.9.att.key.weight', 'blocks.9.att.output.weight', 'blocks.9.att.receptance.weight', 'blocks.9.att.value.weight', 'blocks.9.ffn.key.weight', 'blocks.9.ffn.receptance.weight', 'blocks.9.ffn.value.weight', 'emb.weight', 'head.weight']
1x ['blocks.0.att.ln_x.bias', 'blocks.0.att.ln_x.weight', 'blocks.0.att.time_decay_w1', 'blocks.0.att.time_decay_w2', 'blocks.0.att.time_faaaa', 'blocks.0.att.time_maa_g', 'blocks.0.att.time_maa_k', 'blocks.0.att.time_maa_r', 'blocks.0.att.time_maa_v', 'blocks.0.att.time_maa_w', 'blocks.0.att.time_maa_w1', 'blocks.0.att.time_maa_w2', 'blocks.0.att.time_maa_x', 'blocks.0.ffn.time_maa_k', 'blocks.0.ffn.time_maa_r', 'blocks.0.ln0.bias', 'blocks.0.ln0.weight', 'blocks.0.ln1.bias', 'blocks.0.ln1.weight', 'blocks.0.ln2.bias', 'blocks.0.ln2.weight', 'blocks.1.att.ln_x.bias', 'blocks.1.att.ln_x.weight', 'blocks.1.att.time_decay_w1', 'blocks.1.att.time_decay_w2', 'blocks.1.att.time_faaaa', 'blocks.1.att.time_maa_g', 'blocks.1.att.time_maa_k', 'blocks.1.att.time_maa_r', 'blocks.1.att.time_maa_v', 'blocks.1.att.time_maa_w', 'blocks.1.att.time_maa_w1', 'blocks.1.att.time_maa_w2', 'blocks.1.att.time_maa_x', 'blocks.1.ffn.time_maa_k', 'blocks.1.ffn.time_maa_r', 'blocks.1.ln1.bias', 'blocks.1.ln1.weight', 'blocks.1.ln2.bias', 'blocks.1.ln2.weight', 'blocks.2.att.ln_x.bias', 'blocks.2.att.ln_x.weight', 'blocks.2.att.time_decay_w1', 'blocks.2.att.time_decay_w2', 'blocks.2.att.time_faaaa', 'blocks.2.att.time_maa_g', 'blocks.2.att.time_maa_k', 'blocks.2.att.time_maa_r', 'blocks.2.att.time_maa_v', 'blocks.2.att.time_maa_w', 'blocks.2.att.time_maa_w1', 'blocks.2.att.time_maa_w2', 'blocks.2.att.time_maa_x', 'blocks.2.ffn.time_maa_k', 'blocks.2.ffn.time_maa_r', 'blocks.2.ln1.bias', 'blocks.2.ln1.weight', 'blocks.2.ln2.bias', 'blocks.2.ln2.weight', 'blocks.3.att.ln_x.bias', 'blocks.3.att.ln_x.weight', 'blocks.3.att.time_decay_w1', 'blocks.3.att.time_decay_w2', 'blocks.3.att.time_faaaa', 'blocks.3.att.time_maa_g', 'blocks.3.att.time_maa_k', 'blocks.3.att.time_maa_r', 'blocks.3.att.time_maa_v', 'blocks.3.att.time_maa_w', 'blocks.3.att.time_maa_w1', 'blocks.3.att.time_maa_w2', 'blocks.3.att.time_maa_x', 'blocks.3.ffn.time_maa_k', 'blocks.3.ffn.time_maa_r', 'blocks.3.ln1.bias', 'blocks.3.ln1.weight', 'blocks.3.ln2.bias', 'blocks.3.ln2.weight', 'blocks.4.att.ln_x.bias', 'blocks.4.att.ln_x.weight', 'blocks.4.att.time_decay_w1', 'blocks.4.att.time_decay_w2', 'blocks.4.att.time_faaaa', 'blocks.4.att.time_maa_g', 'blocks.4.att.time_maa_k', 'blocks.4.att.time_maa_r', 'blocks.4.att.time_maa_v', 'blocks.4.att.time_maa_w', 'blocks.4.att.time_maa_w1', 'blocks.4.att.time_maa_w2', 'blocks.4.att.time_maa_x', 'blocks.4.ffn.time_maa_k', 'blocks.4.ffn.time_maa_r', 'blocks.4.ln1.bias', 'blocks.4.ln1.weight', 'blocks.4.ln2.bias', 'blocks.4.ln2.weight', 'blocks.5.att.ln_x.bias', 'blocks.5.att.ln_x.weight', 'blocks.5.att.time_decay_w1', 'blocks.5.att.time_decay_w2', 'blocks.5.att.time_faaaa', 'blocks.5.att.time_maa_g', 'blocks.5.att.time_maa_k', 'blocks.5.att.time_maa_r', 'blocks.5.att.time_maa_v', 'blocks.5.att.time_maa_w', 'blocks.5.att.time_maa_w1', 'blocks.5.att.time_maa_w2', 'blocks.5.att.time_maa_x', 'blocks.5.ffn.time_maa_k', 'blocks.5.ffn.time_maa_r', 'blocks.5.ln1.bias', 'blocks.5.ln1.weight', 'blocks.5.ln2.bias', 'blocks.5.ln2.weight', 'blocks.6.att.ln_x.bias', 'blocks.6.att.ln_x.weight', 'blocks.6.att.time_decay_w1', 'blocks.6.att.time_decay_w2', 'blocks.6.att.time_faaaa', 'blocks.6.att.time_maa_g', 'blocks.6.att.time_maa_k', 'blocks.6.att.time_maa_r', 'blocks.6.att.time_maa_v', 'blocks.6.att.time_maa_w', 'blocks.6.att.time_maa_w1', 'blocks.6.att.time_maa_w2', 'blocks.6.att.time_maa_x', 'blocks.6.ffn.time_maa_k', 'blocks.6.ffn.time_maa_r', 'blocks.6.ln1.bias', 'blocks.6.ln1.weight', 'blocks.6.ln2.bias', 'blocks.6.ln2.weight', 'blocks.7.att.ln_x.bias', 'blocks.7.att.ln_x.weight', 'blocks.7.att.time_decay_w1', 'blocks.7.att.time_decay_w2', 'blocks.7.att.time_faaaa', 'blocks.7.att.time_maa_g', 'blocks.7.att.time_maa_k', 'blocks.7.att.time_maa_r', 'blocks.7.att.time_maa_v', 'blocks.7.att.time_maa_w', 'blocks.7.att.time_maa_w1', 'blocks.7.att.time_maa_w2', 'blocks.7.att.time_maa_x', 'blocks.7.ffn.time_maa_k', 'blocks.7.ffn.time_maa_r', 'blocks.7.ln1.bias', 'blocks.7.ln1.weight', 'blocks.7.ln2.bias', 'blocks.7.ln2.weight', 'blocks.8.att.ln_x.bias', 'blocks.8.att.ln_x.weight', 'blocks.8.att.time_decay_w1', 'blocks.8.att.time_decay_w2', 'blocks.8.att.time_faaaa', 'blocks.8.att.time_maa_g', 'blocks.8.att.time_maa_k', 'blocks.8.att.time_maa_r', 'blocks.8.att.time_maa_v', 'blocks.8.att.time_maa_w', 'blocks.8.att.time_maa_w1', 'blocks.8.att.time_maa_w2', 'blocks.8.att.time_maa_x', 'blocks.8.ffn.time_maa_k', 'blocks.8.ffn.time_maa_r', 'blocks.8.ln1.bias', 'blocks.8.ln1.weight', 'blocks.8.ln2.bias', 'blocks.8.ln2.weight', 'blocks.9.att.ln_x.bias', 'blocks.9.att.ln_x.weight', 'blocks.9.att.time_decay_w1', 'blocks.9.att.time_decay_w2', 'blocks.9.att.time_faaaa', 'blocks.9.att.time_maa_g', 'blocks.9.att.time_maa_k', 'blocks.9.att.time_maa_r', 'blocks.9.att.time_maa_v', 'blocks.9.att.time_maa_w', 'blocks.9.att.time_maa_w1', 'blocks.9.att.time_maa_w2', 'blocks.9.att.time_maa_x', 'blocks.9.ffn.time_maa_k', 'blocks.9.ffn.time_maa_r', 'blocks.9.ln1.bias', 'blocks.9.ln1.weight', 'blocks.9.ln2.bias', 'blocks.9.ln2.weight', 'ln_out.bias', 'ln_out.weight']
2x ['blocks.0.att.time_decay', 'blocks.1.att.time_decay', 'blocks.2.att.time_decay', 'blocks.3.att.time_decay', 'blocks.4.att.time_decay', 'blocks.5.att.time_decay', 'blocks.6.att.time_decay', 'blocks.7.att.time_decay', 'blocks.8.att.time_decay', 'blocks.9.att.time_decay']
3x []
Time to load fused_adam op: 0.20152759552001953 seconds
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...
